**WoodScape: A Multi-task, Multi-camera Fisheye Dataset for Autonomous Driving** is a dataset for instance segmentation, semantic segmentation, and object detection tasks. It is used in the automotive industry. 

The dataset consists of 15000 images with 796503 labeled objects belonging to 46 different classes including *road_surface*, *ego_vehicle*, *construction*, and other: *car*, *pole*, *curb*, *nature*, *green_strip*, *free_space*, *sky*, *person*, *lane_marking*, *other_ground_marking*, *bicycle*, *clean*, *opaque*, *other_wheeled_transport*, *parking_line*, *grouped_vehicles*, *void*, *semi transparent*, *trafficsign_indistingushable*, *rider*, *traffic_sign*, *transparent*, *motorcycle*, *van*, *zebra_crossing*, *fence*, *grouped_pedestrian_and_animals*, *unknown_traffic_light*, *truck*, *bus*, *traffic_light_green*, *movable_object*, *traffic_light_red*, *cats_eyes_and_botts_dots*, *parking_marking*, *train/tram*, *trailer*, *animal*, *traffic_light_yellow*, *grouped_botts_dots*, *caravan*, *grouped_animals*, and *structure*.

Images in the WoodScape: RGB Fisheye dataset have pixel-level instance segmentation annotations. Due to the nature of the instance segmentation task, it can be automatically transformed into a semantic segmentation (only one mask for every class) or object detection (bounding boxes for every object) tasks. There are 1766 (12% of the total) unlabeled images (i.e. without annotations). There are 2 splits in the dataset: *train* (12234 images) and *test* (2766 images). Additionally, every image contains information about its image source (***rgb*** or ***source***), while every instance of the object has ***vehicle info***, ***depiction***, ***glass***, ***occlusion***, and ***position*** tags. The dataset was released in 2021 by the Valeo, France.

Here is a visualized example for randomly selected sample classes:

[Dataset classes](https://github.com/dataset-ninja/woodscape/raw/main/visualizations/classes_preview.webm)
